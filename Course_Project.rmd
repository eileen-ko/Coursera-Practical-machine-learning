---
title: "Practical Machine Learning course project"
author: "Yiqun HUANG"
date: "1/10/2020"
output:
  html_document:
    keep_md: true
  pdf_document: default

---
###Summary
This report is the writeup of Practical Machine Learning course project. The main goal of this project is fitting models to predict the manner that 6 participants performed in the dataset. 

The project is developed in the following content

* Overview of the dataset
* Exploratory data analysis and preprocess of dataset
* Model fitting and validation

###Overview of the dataset
Using devices is now possible to collect a large amount of data about personal activity. In this dataset, six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).
The goal of this project is to predict the manner in which they did the exercise, which is the "classe" variable in the training set. 

Load dataset and packages will be used in the project
```{r, echo=TRUE}
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(dplyr)

set.seed(113311)

setwd("~/Documents/Coursera R/Pratical Machine Learning/Course Project")
pml.training <- read.csv("~/Documents/Coursera R/Pratical Machine Learning/Course Project/pml-training.csv")
pml.testing <- read.csv("~/Documents/Coursera R/Pratical Machine Learning/Course Project/pml-testing.csv")
```

Take a brief look at the training dataset
```{r, echo=TRUE}
sum(is.na(pml.training))
```

Creat a partition with the training dataset
```{r, echo=TRUE}
inTrain <- createDataPartition(y=pml.training$classe, p=0.75, list=FALSE)
training <- pml.training[inTrain,]
testing <- pml.training[-inTrain,]
```

There are 1287472 NA in the training dataset. We need to remove variables that are unbalanced/near zero variance, as well as the variables that are mostly NA.
```{r, echo=TRUE}
nzv <- nearZeroVar(training)
filteredtraining <- training[, -nzv]
filteredtesting <- testing[, -nzv]

removena <- sapply(filteredtraining, function(x) mean(is.na(x))) > 0.95
TrainSet <- filteredtraining[, removena==FALSE]
TestSet <- filteredtesting[, removena==FALSE]
```

###Data processing
Remove the variables are identification information. (participant name)
```{r, echo=TRUE}
TrainSet <- TrainSet[, -(1:6)]
TestSet <- TestSet[, -(1:6)]
```

Find out highly correlated variables using cor function
```{r, echo=TRUE}
cor <- cor(TrainSet[ ,-53])
which(cor >0.85, arr.ind = TRUE)
```

```{r, echo=TRUE}
names(TrainSet[c(1, 4, 8, 9, 11)])
```

creat the new training and testing dataset omitted the above highly correlated variables
```{r, echo=TRUE}
TrainSet <- TrainSet[-c(1, 4, 8, 9, 11)]
TestSet <- TestSet[-c(1, 4, 8, 9, 11)]
```

###Model fitting
In this project, 3 mostly used classification algorithms in Machine Learnin will be trained. a) Classification trees b) Random forrest c)Boosting trees
###Classification trees
```{r, echo=TRUE}
FitDT <- rpart(classe ~ ., data= TrainSet, method="class")
fancyRpartPlot(FitDT)
```
Validate the accuracy by using TestSet
```{r, echo=TRUE}
predictFitDT <- predict(FitDT, TestSet, type = "class")
DecisionTree <- confusionMatrix(predictFitDT, TestSet$classe)
DecisionTree
```
The accuracy is 0.6986, which is quite low and only a little better than guessing.

###Random forrest
With the low accuracy of single classfication tree model, Random forrest could be a much powerful model since it contains random decision trees.
```{r, echo=TRUE}
controlRF <- trainControl(method="cv", number=3, verboseIter=FALSE)
FitRf <- train(classe ~ ., data=TrainSet, 
                          method="rf", trControl=controlRF)
FitRf$finalModel
```
Use the TestSet to predict classe~ and validate accuracy
```{r, echo=TRUE}
predictRf <- predict(FitRf, newdata=TestSet)
confRf <- confusionMatrix(predictRf, TestSet$classe)
confRf
```
The accuracy is very high 0.99. We need to consider over-fitting.

###Boosting trees
```{r, echo=TRUE}
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
modGBM  <- train(classe ~ ., data=TrainSet, method = "gbm", trControl = controlGBM, verbose = FALSE)
modGBM$finalModel
modGBM
```

###validate the accuracy with GBM
```{r, echo=TRUE}
predictGBM <- predict(modGBM, newdata=TestSet)
cmGBM <- confusionMatrix(predictGBM, TestSet$classe)
cmGBM
```
The accuracy is 0.9621.
Overall, Random Forrest has the highest accuracy.

###Apply trained models to testing dataset
```{r, echo=TRUE}
quiz <- predict(FitRf, newdata = pml.testing)
quiz
quiz1 <- predict(modGBM, newdata = pml.testing)
quiz1
```
Case 6 has different result on different models. 
